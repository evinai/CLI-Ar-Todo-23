{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/evinai/CLI-Ar-Todo-23/blob/master/2_5_Practice_Fundamentals_Most_Basic_Form_of_Training_LLMs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice Fundamentals: Most Basic Form of Training LLMs 💪\n",
        "\n",
        "## Learning Objectives 🎯\n",
        "- Set up the development environment to utilize GPU resources.\n",
        "- Understand and install specific library versions directly from a repository.\n",
        "- Familiarize with YAML configuration for training setups.\n",
        "- Execute a basic training session for a language model using the Axolotl library."
      ],
      "metadata": {
        "id": "GrzSluAyj1F-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GPU Verification ✅\n",
        "Check for the availability of a GPU. A free-tier T4 GPU is sufficient for running this notebook, which makes it accessible without needing high-end hardware."
      ],
      "metadata": {
        "id": "6VcnTG3SV_Q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==2.4.0"
      ],
      "metadata": {
        "id": "Y4ucWAMuaIsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SWqOvsFTmg8V",
        "outputId": "85714494-959b-434b-9beb-8ce5d079fc29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: conda: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "# Check so there is a gpu available, a T4(free tier) is enough to run this notebook\n",
        "assert (torch.cuda.is_available()==True)"
      ],
      "metadata": {
        "id": "7sGUU2WWKiTy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library Installation 🛠️\n",
        "Install the Axolotl library directly from GitHub to ensure compatibility with the course's specified version. This step ensures that the environment matches the course requirements without needing advanced hardware."
      ],
      "metadata": {
        "id": "VzSK5YjoWB4y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e 'git+https://github.com/axolotl-ai-cloud/axolotl.git@78b42a3fe13c49e317bc116b9999c30e070322cc#egg=axolotl' # ensures the same version we used in the course"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTRnNMOSj6Bb",
        "outputId": "f9723fa9-1370-4788-ba70-ff523b1e63c7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining axolotl from git+https://github.com/axolotl-ai-cloud/axolotl.git@78b42a3fe13c49e317bc116b9999c30e070322cc#egg=axolotl\n",
            "  Cloning https://github.com/axolotl-ai-cloud/axolotl.git (to revision 78b42a3fe13c49e317bc116b9999c30e070322cc) to ./src/axolotl\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/axolotl-ai-cloud/axolotl.git /content/src/axolotl\n",
            "  Running command git rev-parse -q --verify 'sha^78b42a3fe13c49e317bc116b9999c30e070322cc'\n",
            "  Running command git fetch -q https://github.com/axolotl-ai-cloud/axolotl.git 78b42a3fe13c49e317bc116b9999c30e070322cc\n",
            "  Running command git checkout -q 78b42a3fe13c49e317bc116b9999c30e070322cc\n",
            "  Resolved https://github.com/axolotl-ai-cloud/axolotl.git to commit 78b42a3fe13c49e317bc116b9999c30e070322cc\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting transformers@ git+https://github.com/huggingface/transformers.git@026a173a64372e9602a16523b8fae9de4b0ff428 (from axolotl)\n",
            "  Cloning https://github.com/huggingface/transformers.git (to revision 026a173a64372e9602a16523b8fae9de4b0ff428) to /tmp/pip-install-8hh7intt/transformers_2bc2970b6141491c81a115551b992656\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-install-8hh7intt/transformers_2bc2970b6141491c81a115551b992656\n",
            "  Running command git rev-parse -q --verify 'sha^026a173a64372e9602a16523b8fae9de4b0ff428'\n",
            "  Running command git fetch -q https://github.com/huggingface/transformers.git 026a173a64372e9602a16523b8fae9de4b0ff428\n",
            "  Running command git checkout -q 026a173a64372e9602a16523b8fae9de4b0ff428\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 026a173a64372e9602a16523b8fae9de4b0ff428\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fschat@ git+https://github.com/lm-sys/FastChat.git@27a05b04a35510afb1d767ae7e5990cbd278f8fe (from axolotl)\n",
            "  Cloning https://github.com/lm-sys/FastChat.git (to revision 27a05b04a35510afb1d767ae7e5990cbd278f8fe) to /tmp/pip-install-8hh7intt/fschat_9f7d70518d7a4102a90be08875c6cb9e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/lm-sys/FastChat.git /tmp/pip-install-8hh7intt/fschat_9f7d70518d7a4102a90be08875c6cb9e\n",
            "  Running command git rev-parse -q --verify 'sha^27a05b04a35510afb1d767ae7e5990cbd278f8fe'\n",
            "  Running command git fetch -q https://github.com/lm-sys/FastChat.git 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
            "  Running command git checkout -q 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
            "  Resolved https://github.com/lm-sys/FastChat.git to commit 27a05b04a35510afb1d767ae7e5990cbd278f8fe\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting packaging==23.2 (from axolotl)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting peft==0.11.1 (from axolotl)\n",
            "  Downloading peft-0.11.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting tokenizers==0.19.1 (from axolotl)\n",
            "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting bitsandbytes==0.43.3 (from axolotl)\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting accelerate==0.32.0 (from axolotl)\n",
            "  Downloading accelerate-0.32.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting pydantic==2.6.3 (from axolotl)\n",
            "  Downloading pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from axolotl)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting fire (from axolotl)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.10/dist-packages (from axolotl) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from axolotl) (2.32.3)\n",
            "Collecting datasets==2.19.1 (from axolotl)\n",
            "  Downloading datasets-2.19.1-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from axolotl) (0.2.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from axolotl) (0.19.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from axolotl) (0.8.0)\n",
            "Collecting xformers==0.0.27 (from axolotl)\n",
            "  Downloading xformers-0.0.27-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting optimum==1.16.2 (from axolotl)\n",
            "  Downloading optimum-1.16.2-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting hf_transfer (from axolotl)\n",
            "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting colorama (from axolotl)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from axolotl) (0.60.0)\n",
            "Requirement already satisfied: numpy>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from axolotl) (1.26.4)\n",
            "Collecting evaluate==0.4.1 (from axolotl)\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from axolotl) (1.13.1)\n",
            "Collecting scikit-learn==1.2.2 (from axolotl)\n",
            "  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting pynvml (from axolotl)\n",
            "  Downloading pynvml-12.0.0-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting art (from axolotl)\n",
            "  Downloading art-6.4-py3-none-any.whl.metadata (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==3.50.2 (from axolotl)\n",
            "  Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from axolotl) (2.17.1)\n",
            "Collecting python-dotenv==1.0.1 (from axolotl)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting autoawq>=0.2.5 (from axolotl)\n",
            "  Downloading autoawq-0.2.7.post3-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting s3fs (from axolotl)\n",
            "  Downloading s3fs-2024.12.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: gcsfs in /usr/local/lib/python3.10/dist-packages (from axolotl) (2024.10.0)\n",
            "Collecting trl==0.9.6 (from axolotl)\n",
            "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting zstandard==0.22.0 (from axolotl)\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.10/dist-packages (from axolotl) (1.7.27)\n",
            "Requirement already satisfied: torch==2.5.1+cu121 in /usr/local/lib/python3.10/dist-packages (from axolotl) (2.5.1+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.32.0->axolotl) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.32.0->axolotl) (0.27.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.32.0->axolotl) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1->axolotl) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1->axolotl) (17.0.0)\n",
            "Collecting pyarrow-hotfix (from datasets==2.19.1->axolotl)\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==2.19.1->axolotl)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1->axolotl) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1->axolotl) (4.67.1)\n",
            "Collecting xxhash (from datasets==2.19.1->axolotl)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets==2.19.1->axolotl)\n",
            "  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.3.1,>=2023.1.0 (from fsspec[http]<=2024.3.1,>=2023.1.0->datasets==2.19.1->axolotl)\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.19.1->axolotl) (3.11.10)\n",
            "Collecting responses<0.19 (from evaluate==0.4.1->axolotl)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.50.2->axolotl)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl) (5.5.0)\n",
            "Collecting fastapi (from gradio==3.50.2->axolotl)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio==3.50.2->axolotl)\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==0.6.1 (from gradio==3.50.2->axolotl)\n",
            "  Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio==3.50.2->axolotl)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl) (3.8.0)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl) (3.10.12)\n",
            "Collecting pillow<11.0,>=8.0 (from gradio==3.50.2->axolotl)\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pydub (from gradio==3.50.2->axolotl)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart (from gradio==3.50.2->axolotl)\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==3.50.2->axolotl)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.50.2->axolotl)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio==3.50.2->axolotl)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting coloredlogs (from optimum==1.16.2->axolotl)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum==1.16.2->axolotl) (1.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.3->axolotl) (0.7.0)\n",
            "Collecting pydantic-core==2.16.3 (from pydantic==2.6.3->axolotl)\n",
            "  Downloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->axolotl) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->axolotl) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1+cu121->axolotl) (3.4.2)\n",
            "Collecting tyro>=0.5.11 (from trl==0.9.6->axolotl)\n",
            "  Downloading tyro-0.9.5-py3-none-any.whl.metadata (9.4 kB)\n",
            "INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
            "\u001b[31mERROR: Cannot install axolotl and axolotl==0.4.1 because these package versions have conflicting dependencies.\u001b[0m\u001b[31m\n",
            "\u001b[0m\n",
            "The conflict is caused by:\n",
            "    axolotl 0.4.1 depends on torch==2.5.1+cu121\n",
            "    accelerate 0.32.0 depends on torch>=1.10.0\n",
            "    bitsandbytes 0.43.3 depends on torch\n",
            "    optimum 1.16.2 depends on torch>=1.11\n",
            "    peft 0.11.1 depends on torch>=1.13.0\n",
            "    trl 0.9.6 depends on torch>=1.4.0\n",
            "    xformers 0.0.27 depends on torch==2.3.1\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "\u001b[31mERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install --no-build-isolation axolotl[flash-attn,deepspeed]"
      ],
      "metadata": {
        "id": "aLai0LprlEcx",
        "outputId": "4ecd9afe-3243-42c9-de79-8480a5370df7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting axolotl[deepspeed,flash-attn]\n",
            "  Downloading axolotl-0.6.0.tar.gz (2.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/2.0 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bitsandbytes==0.45.0 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl.metadata (2.9 kB)\n",
            "Collecting triton>=2.3.0 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting liger-kernel==0.4.2 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading liger_kernel-0.4.2-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting packaging==23.2 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: peft==0.14.0 in /usr/local/lib/python3.10/dist-packages (from axolotl[deepspeed,flash-attn]) (0.14.0)\n",
            "Requirement already satisfied: transformers>=4.46.3 in /usr/local/lib/python3.10/dist-packages (from axolotl[deepspeed,flash-attn]) (4.47.1)\n",
            "Requirement already satisfied: tokenizers>=0.20.1 in /usr/local/lib/python3.10/dist-packages (from axolotl[deepspeed,flash-attn]) (0.21.0)\n",
            "Collecting accelerate==1.2.0 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading accelerate-1.2.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting datasets==3.1.0 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting pydantic==2.6.3 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading pydantic-2.6.3-py3-none-any.whl.metadata (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.4/84.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading addict-2.4.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting fire (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: PyYAML>=6.0 in /usr/local/lib/python3.10/dist-packages (from axolotl[deepspeed,flash-attn]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from axolotl[deepspeed,flash-attn]) (2.32.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from axolotl[deepspeed,flash-attn]) (0.2.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (from axolotl[deepspeed,flash-attn]) (0.19.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from axolotl[deepspeed,flash-attn]) (0.8.0)\n",
            "Collecting optimum==1.16.2 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading optimum-1.16.2-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting hf-transfer (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting colorama (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from axolotl[deepspeed,flash-attn]) (0.60.0)\n",
            "Requirement already satisfied: numpy<=2.0.1,>=1.24.4 in /usr/local/lib/python3.10/dist-packages (from axolotl[deepspeed,flash-attn]) (1.26.4)\n",
            "Collecting evaluate==0.4.1 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading evaluate-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from axolotl[deepspeed,flash-attn]) (1.13.1)\n",
            "Collecting scikit-learn==1.4.2 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Collecting nvidia-ml-py==12.560.30 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading nvidia_ml_py-12.560.30-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting art (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading art-6.4-py3-none-any.whl.metadata (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==3.50.2 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from axolotl[deepspeed,flash-attn]) (2.17.1)\n",
            "Collecting python-dotenv==1.0.1 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting s3fs>=2024.5.0 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading s3fs-2024.12.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: gcsfs>=2024.5.0 in /usr/local/lib/python3.10/dist-packages (from axolotl[deepspeed,flash-attn]) (2024.10.0)\n",
            "Collecting trl==0.12.1 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading trl-0.12.1-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting zstandard==0.22.0 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: fastcore in /usr/local/lib/python3.10/dist-packages (from axolotl[deepspeed,flash-attn]) (1.7.27)\n",
            "Collecting lm-eval==0.4.4 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading lm_eval-0.4.4-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langdetect==1.0.9 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting immutabledict==4.2.0 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading immutabledict-4.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting antlr4-python3-runtime==4.13.2 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading antlr4_python3_runtime-4.13.2-py3-none-any.whl.metadata (304 bytes)\n",
            "Collecting torchao==0.5.0 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading torchao-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting schedulefree==1.3.0 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading schedulefree-1.3.tar.gz (20 kB)\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch==2.5.1+cu121 in /usr/local/lib/python3.10/dist-packages (from axolotl[deepspeed,flash-attn]) (2.5.1+cu121)\n",
            "Collecting xformers==0.0.28.post3 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting deepspeed==0.16.1 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading deepspeed-0.16.1.tar.gz (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting deepspeed-kernels (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading deepspeed_kernels-0.0.1.dev1698255861-py3-none-manylinux1_x86_64.whl.metadata (680 bytes)\n",
            "Collecting flash-attn==2.7.0.post2 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading flash_attn-2.7.0.post2.tar.gz (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m84.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==1.2.0->axolotl[deepspeed,flash-attn]) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.2.0->axolotl[deepspeed,flash-attn]) (0.27.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate==1.2.0->axolotl[deepspeed,flash-attn]) (0.4.5)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.45.0->axolotl[deepspeed,flash-attn]) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0->axolotl[deepspeed,flash-attn]) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0->axolotl[deepspeed,flash-attn]) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets==3.1.0->axolotl[deepspeed,flash-attn])\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0->axolotl[deepspeed,flash-attn]) (2.2.2)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0->axolotl[deepspeed,flash-attn]) (4.67.1)\n",
            "Collecting xxhash (from datasets==3.1.0->axolotl[deepspeed,flash-attn])\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets==3.1.0->axolotl[deepspeed,flash-attn])\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets==3.1.0->axolotl[deepspeed,flash-attn])\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==3.1.0->axolotl[deepspeed,flash-attn]) (3.11.10)\n",
            "Collecting hjson (from deepspeed==0.16.1->axolotl[deepspeed,flash-attn])\n",
            "  Downloading hjson-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.16.1->axolotl[deepspeed,flash-attn]) (1.1.0)\n",
            "Collecting ninja (from deepspeed==0.16.1->axolotl[deepspeed,flash-attn])\n",
            "  Using cached ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from deepspeed==0.16.1->axolotl[deepspeed,flash-attn]) (9.0.0)\n",
            "Collecting responses<0.19 (from evaluate==0.4.1->axolotl[deepspeed,flash-attn])\n",
            "  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.50.2->axolotl[deepspeed,flash-attn])\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (5.5.0)\n",
            "Collecting fastapi (from gradio==3.50.2->axolotl[deepspeed,flash-attn])\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio==3.50.2->axolotl[deepspeed,flash-attn])\n",
            "  Downloading ffmpy-0.5.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting gradio-client==0.6.1 (from gradio==3.50.2->axolotl[deepspeed,flash-attn])\n",
            "  Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.28.1)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (6.4.5)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio==3.50.2->axolotl[deepspeed,flash-attn])\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (3.8.0)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.2->axolotl[deepspeed,flash-attn]) (3.10.12)\n",
            "Collecting pillow<11.0,>=8.0 (from gradio==3.50.2->axolotl[deepspeed,flash-attn])\n",
            "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Collecting pydub (from gradio==3.50.2->axolotl[deepspeed,flash-attn])\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart (from gradio==3.50.2->axolotl[deepspeed,flash-attn])\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==3.50.2->axolotl[deepspeed,flash-attn])\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.50.2->axolotl[deepspeed,flash-attn])\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio==3.50.2->axolotl[deepspeed,flash-attn])\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect==1.0.9->axolotl[deepspeed,flash-attn]) (1.17.0)\n",
            "Collecting jsonlines (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn])\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (2.10.2)\n",
            "Collecting pybind11>=2.6.2 (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn])\n",
            "  Downloading pybind11-2.13.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Collecting pytablewriter (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn])\n",
            "  Downloading pytablewriter-1.2.0-py3-none-any.whl.metadata (37 kB)\n",
            "Collecting rouge-score>=0.0.4 (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn])\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu>=1.5.0 (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn])\n",
            "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlitedict (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn])\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tqdm-multiprocess (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn])\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting word2number (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn])\n",
            "  Downloading word2number-1.1.zip (9.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (10.5.0)\n",
            "Collecting coloredlogs (from optimum==1.16.2->axolotl[deepspeed,flash-attn])\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum==1.16.2->axolotl[deepspeed,flash-attn]) (1.13.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic==2.6.3->axolotl[deepspeed,flash-attn]) (0.7.0)\n",
            "Collecting pydantic-core==2.16.3 (from pydantic==2.6.3->axolotl[deepspeed,flash-attn])\n",
            "  Downloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2->axolotl[deepspeed,flash-attn]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.4.2->axolotl[deepspeed,flash-attn]) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.5.1+cu121->axolotl[deepspeed,flash-attn]) (3.4.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from trl==0.12.1->axolotl[deepspeed,flash-attn]) (13.9.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum==1.16.2->axolotl[deepspeed,flash-attn]) (1.3.0)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (4.4.2)\n",
            "INFO: pip is looking at multiple versions of gcsfs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gcsfs>=2024.5.0 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading gcsfs-2024.12.0-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading gcsfs-2024.9.0.post1-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.2.1)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (from gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.19.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl[deepspeed,flash-attn]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl[deepspeed,flash-attn]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl[deepspeed,flash-attn]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->axolotl[deepspeed,flash-attn]) (2024.12.14)\n",
            "Collecting aiobotocore<3.0.0,>=2.5.4 (from s3fs>=2024.5.0->axolotl[deepspeed,flash-attn])\n",
            "  Downloading aiobotocore-2.16.1-py3-none-any.whl.metadata (23 kB)\n",
            "INFO: pip is looking at multiple versions of s3fs to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting s3fs>=2024.5.0 (from axolotl[deepspeed,flash-attn])\n",
            "  Downloading s3fs-2024.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading s3fs-2024.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.46.3->axolotl[deepspeed,flash-attn]) (2024.11.6)\n",
            "Requirement already satisfied: cmake>=3.24 in /usr/local/lib/python3.10/dist-packages (from deepspeed-kernels->axolotl[deepspeed,flash-attn]) (3.31.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->axolotl[deepspeed,flash-attn]) (2.5.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->axolotl[deepspeed,flash-attn]) (0.43.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (1.68.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (75.1.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->axolotl[deepspeed,flash-attn]) (3.1.3)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[deepspeed,flash-attn]) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[deepspeed,flash-attn]) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[deepspeed,flash-attn]) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[deepspeed,flash-attn]) (4.3.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[deepspeed,flash-attn]) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb->axolotl[deepspeed,flash-attn]) (1.3.4)\n",
            "Collecting botocore<1.35.89,>=1.35.74 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[deepspeed,flash-attn])\n",
            "  Downloading botocore-1.35.88-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.10.10 in /usr/local/lib/python3.10/dist-packages (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.17.0)\n",
            "Collecting aioitertools<1.0.0,>=0.5.1 (from aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[deepspeed,flash-attn])\n",
            "  Downloading aioitertools-0.12.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (1.3.2)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (1.18.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (1.18.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->axolotl[deepspeed,flash-attn]) (4.0.11)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.2->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (4.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==3.1.0->axolotl[deepspeed,flash-attn]) (2024.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (3.9.1)\n",
            "Collecting portalocker (from sacrebleu>=1.5.0->lm-eval==0.4.4->axolotl[deepspeed,flash-attn])\n",
            "  Downloading portalocker-3.0.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (0.9.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu>=1.5.0->lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (5.3.0)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.14.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->optimum==1.16.2->axolotl[deepspeed,flash-attn])\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi->gradio==3.50.2->axolotl[deepspeed,flash-attn])\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.3.1)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (1.0.7)\n",
            "Collecting DataProperty<2,>=1.0.1 (from pytablewriter->lm-eval==0.4.4->axolotl[deepspeed,flash-attn])\n",
            "  Downloading DataProperty-1.0.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm-eval==0.4.4->axolotl[deepspeed,flash-attn])\n",
            "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm-eval==0.4.4->axolotl[deepspeed,flash-attn])\n",
            "  Downloading pathvalidate-3.2.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm-eval==0.4.4->axolotl[deepspeed,flash-attn])\n",
            "  Downloading tabledata-1.3.3-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm-eval==0.4.4->axolotl[deepspeed,flash-attn])\n",
            "  Downloading tcolorpy-0.1.6-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting typepy<2,>=1.3.2 (from typepy[datetime]<2,>=1.3.2->pytablewriter->lm-eval==0.4.4->axolotl[deepspeed,flash-attn])\n",
            "  Downloading typepy-1.3.2-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl==0.12.1->axolotl[deepspeed,flash-attn]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->trl==0.12.1->axolotl[deepspeed,flash-attn]) (2.18.0)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from botocore<1.35.89,>=1.35.74->aiobotocore<3.0.0,>=2.5.4->s3fs>=2024.5.0->axolotl[deepspeed,flash-attn])\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->axolotl[deepspeed,flash-attn]) (5.0.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (1.25.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (0.22.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->trl==0.12.1->axolotl[deepspeed,flash-attn]) (0.1.2)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm-eval==0.4.4->axolotl[deepspeed,flash-attn]) (5.2.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs>=2024.5.0->axolotl[deepspeed,flash-attn]) (3.2.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx->gradio==3.50.2->axolotl[deepspeed,flash-attn]) (1.2.2)\n",
            "Downloading accelerate-1.2.0-py3-none-any.whl (336 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m336.3/336.3 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading antlr4_python3_runtime-4.13.2-py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.5/144.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.45.0-py3-none-manylinux_2_24_x86_64.whl (69.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.1.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m40.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading evaluate-0.4.1-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading immutabledict-4.2.0-py3-none-any.whl (4.7 kB)\n",
            "Downloading liger_kernel-0.4.2-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lm_eval-0.4.4-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m81.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_ml_py-12.560.30-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimum-1.16.2-py3-none-any.whl (402 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m402.5/402.5 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.6.3-py3-none-any.whl (395 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.2/395.2 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m116.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchao-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.12.1-py3-none-any.whl (310 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.9/310.9 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.28.post3-cp310-cp310-manylinux_2_28_x86_64.whl (16.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.7/16.7 MB\u001b[0m \u001b[31m102.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m112.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m90.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gcsfs-2024.9.0.post1-py2.py3-none-any.whl (34 kB)\n",
            "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading s3fs-2024.9.0-py3-none-any.whl (29 kB)\n",
            "Downloading triton-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Downloading art-6.4-py3-none-any.whl (608 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.6/608.6 kB\u001b[0m \u001b[31m46.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading deepspeed_kernels-0.0.1.dev1698255861-py3-none-manylinux1_x86_64.whl (44.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiobotocore-2.16.1-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybind11-2.13.6-py3-none-any.whl (243 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.3/243.3 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Downloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.5.0-py3-none-any.whl (6.0 kB)\n",
            "Downloading hjson-3.1.0-py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Using cached ninja-1.11.1.3-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aioitertools-0.12.0-py3-none-any.whl (24 kB)\n",
            "Downloading botocore-1.35.88-py3-none-any.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
            "Downloading pathvalidate-3.2.1-py3-none-any.whl (23 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
            "Downloading tcolorpy-0.1.6-py3-none-any.whl (8.1 kB)\n",
            "Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
            "Downloading portalocker-3.0.0-py3-none-any.whl (19 kB)\n",
            "Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Building wheels for collected packages: deepspeed, flash-attn, langdetect, schedulefree, axolotl, fire, rouge-score, sqlitedict, word2number\n",
            "  Building wheel for deepspeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deepspeed: filename=deepspeed-0.16.1-py3-none-any.whl size=1543910 sha256=4a52323c0fc25ccf6117da922e8c1f6eedb1beb4f12237fdf83e0a5605daefac\n",
            "  Stored in directory: /root/.cache/pip/wheels/e8/a6/09/09e982334b832b202b1752644a6b314b922eb3897416846b7e\n",
            "  Building wheel for flash-attn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flash-attn: filename=flash_attn-2.7.0.post2-cp310-cp310-linux_x86_64.whl size=183291101 sha256=16a849d51b95cf8e47a6e6cd36826e9ffbbc068a8546e7e3501a598bd70905a6\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/e3/ed/5e845387d52f2debd1bafb847bf3d774d3f0a3c8e31b1dc948\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993222 sha256=9d2fbb1a14c825386611d7933982ef8c411942d979667f7036293236b8f077ce\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "  Building wheel for schedulefree (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for schedulefree: filename=schedulefree-1.3-py3-none-any.whl size=33053 sha256=6f1436fb077945daeefcfe5d8c430960f6b88369e0b3213cb165ad368237d755\n",
            "  Stored in directory: /root/.cache/pip/wheels/b6/71/45/2379117a07d20261d74cde321cf89fc4ae660bf8ab378a24d2\n",
            "  Building wheel for axolotl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for axolotl: filename=axolotl-0.6.0-py3-none-any.whl size=284988 sha256=f81f5ac7130b99830e64bef349b6b0b6de5d7840fe9e012f043c19af7ea1814d\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/4c/6c/8ffcfbe90f1d4314efeaeeacd821b043c51ca7d452fac61b01\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=5e6bfabd51a911e6158355e7b1a202610d4eb6cad4b3fb00d87bdab917284460\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/39/2f/2d3cadc408a8804103f1c34ddd4b9f6a93497b11fa96fe738e\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=5af61d93eab2ca0acbc36096f32ac9f4645cb388edc3c71dddd3c50e4207bf59\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16864 sha256=699d1cf44002c4eaf91f1cd82c417341da8a87c8e7474d42d733745e72ac1b0f\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for word2number: filename=word2number-1.1-py3-none-any.whl size=5568 sha256=d0044ae2ea368686156f966a925a0b72ae41e9191e09086bdd1d2d6a6c045fc7\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/ff/26/d3cfbd971e96c5aa3737ecfced81628830d7359b55fbb8ca3b\n",
            "Successfully built deepspeed flash-attn langdetect schedulefree axolotl fire rouge-score sqlitedict word2number\n",
            "Installing collected packages: word2number, torchao, sqlitedict, pydub, nvidia-ml-py, hjson, antlr4-python3-runtime, addict, zstandard, xxhash, websockets, uvicorn, triton, tcolorpy, semantic-version, schedulefree, python-multipart, python-dotenv, pydantic-core, pybind11, portalocker, pillow, pathvalidate, packaging, ninja, mbstrdecoder, markupsafe, langdetect, jsonlines, jmespath, immutabledict, humanfriendly, hf-transfer, fsspec, fire, ffmpy, dill, colorama, art, aioitertools, aiofiles, typepy, tqdm-multiprocess, starlette, scikit-learn, sacrebleu, rouge-score, responses, pydantic, multiprocess, deepspeed-kernels, coloredlogs, botocore, gradio-client, fastapi, xformers, liger-kernel, flash-attn, deepspeed, DataProperty, bitsandbytes, aiobotocore, accelerate, tabledata, s3fs, gradio, datasets, trl, pytablewriter, optimum, gcsfs, evaluate, lm-eval, axolotl\n",
            "  Attempting uninstall: websockets\n",
            "    Found existing installation: websockets 14.1\n",
            "    Uninstalling websockets-14.1:\n",
            "      Successfully uninstalled websockets-14.1\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.1\n",
            "    Uninstalling pydantic_core-2.27.1:\n",
            "      Successfully uninstalled pydantic_core-2.27.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.0.0\n",
            "    Uninstalling pillow-11.0.0:\n",
            "      Successfully uninstalled pillow-11.0.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.2\n",
            "    Uninstalling packaging-24.2:\n",
            "      Successfully uninstalled packaging-24.2\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: immutabledict\n",
            "    Found existing installation: immutabledict 4.2.1\n",
            "    Uninstalling immutabledict-4.2.1:\n",
            "      Successfully uninstalled immutabledict-4.2.1\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.0\n",
            "    Uninstalling scikit-learn-1.6.0:\n",
            "      Successfully uninstalled scikit-learn-1.6.0\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.3\n",
            "    Uninstalling pydantic-2.10.3:\n",
            "      Successfully uninstalled pydantic-2.10.3\n",
            "  Attempting uninstall: accelerate\n",
            "    Found existing installation: accelerate 1.2.1\n",
            "    Uninstalling accelerate-1.2.1:\n",
            "      Successfully uninstalled accelerate-1.2.1\n",
            "  Attempting uninstall: gcsfs\n",
            "    Found existing installation: gcsfs 2024.10.0\n",
            "    Uninstalling gcsfs-2024.10.0:\n",
            "      Successfully uninstalled gcsfs-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 2.6.3 which is incompatible.\n",
            "google-genai 0.3.0 requires websockets<15.0dev,>=13.0, but you have websockets 11.0.3 which is incompatible.\n",
            "langchain 0.3.12 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 2.6.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed DataProperty-1.0.1 accelerate-1.2.0 addict-2.4.0 aiobotocore-2.16.1 aiofiles-23.2.1 aioitertools-0.12.0 antlr4-python3-runtime-4.13.2 art-6.4 axolotl-0.6.0 bitsandbytes-0.45.0 botocore-1.35.88 colorama-0.4.6 coloredlogs-15.0.1 datasets-3.1.0 deepspeed-0.16.1 deepspeed-kernels-0.0.1.dev1698255861 dill-0.3.8 evaluate-0.4.1 fastapi-0.115.6 ffmpy-0.5.0 fire-0.7.0 flash-attn-2.7.0.post2 fsspec-2024.9.0 gcsfs-2024.9.0.post1 gradio-3.50.2 gradio-client-0.6.1 hf-transfer-0.1.8 hjson-3.1.0 humanfriendly-10.0 immutabledict-4.2.0 jmespath-1.0.1 jsonlines-4.0.0 langdetect-1.0.9 liger-kernel-0.4.2 lm-eval-0.4.4 markupsafe-2.1.5 mbstrdecoder-1.1.3 multiprocess-0.70.16 ninja-1.11.1.3 nvidia-ml-py-12.560.30 optimum-1.16.2 packaging-23.2 pathvalidate-3.2.1 pillow-10.4.0 portalocker-3.0.0 pybind11-2.13.6 pydantic-2.6.3 pydantic-core-2.16.3 pydub-0.25.1 pytablewriter-1.2.0 python-dotenv-1.0.1 python-multipart-0.0.20 responses-0.18.0 rouge-score-0.1.2 s3fs-2024.9.0 sacrebleu-2.4.3 schedulefree-1.3 scikit-learn-1.4.2 semantic-version-2.10.0 sqlitedict-2.1.0 starlette-0.41.3 tabledata-1.3.3 tcolorpy-0.1.6 torchao-0.5.0 tqdm-multiprocess-0.0.11 triton-3.1.0 trl-0.12.1 typepy-1.3.2 uvicorn-0.34.0 websockets-11.0.3 word2number-1.1 xformers-0.0.28.post3 xxhash-3.5.0 zstandard-0.22.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "ca67e26e915a49f79cf7888bb7668dd0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration Setup 📝\n",
        "Create a YAML configuration to meticulously set up the training parameters. This configuration file will include settings for the model, tokenizer, and training details, structured to work efficiently even on less powerful, free-tier GPUs."
      ],
      "metadata": {
        "id": "D8ooQasQWE9l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "9zrTS3fvjvW7"
      },
      "outputs": [],
      "source": [
        "import yaml\n",
        "\n",
        "train_config = \"\"\"\n",
        "# model params\n",
        "base_model: TinyLlama/TinyLlama-1.1B-Chat-v1.0\n",
        "model_type: LlamaForCausalLM\n",
        "tokenizer_type: LlamaTokenizer\n",
        "\n",
        "\n",
        "# dataset params\n",
        "datasets:\n",
        "  - path: jaydenccc/AI_Storyteller_Dataset\n",
        "    type:\n",
        "      system_prompt: \"\"\n",
        "      field_system: system\n",
        "      field_instruction: synopsis\n",
        "      field_output: short_story\n",
        "      format: \"<|user|>\\n {instruction} </s>\\n<|assistant|>\"\n",
        "      no_input_format: \"<|user|> {instruction} </s>\\n<|assistant|>\"\n",
        "\n",
        "output_dir: ./models/evinai_TinyLlama_Storyteller\n",
        "\n",
        "# model params\n",
        "sequence_length: 1024\n",
        "bf16: auto\n",
        "tf32: false\n",
        "\n",
        "# training params\n",
        "batch_size: 4\n",
        "micro_batch_size: 4\n",
        "num_epochs: 2\n",
        "optimizer: adamw_bnb_8bit\n",
        "learning_rate: 0.0002\n",
        "\n",
        "logging_steps: 1\n",
        "\"\"\"\n",
        "\n",
        "# Convert the YAML string to a Python dictionary\n",
        "yaml_dict = yaml.safe_load(train_config)\n",
        "\n",
        "\n",
        "# Write the YAML file\n",
        "with open(\"basic_train.yml\", 'w') as file:\n",
        "    yaml.dump(yaml_dict, file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Launch 🚀\n",
        "Launch the training process with the `accelerate` command. This command is optimized for use even with free-tier resources, ensuring that you can train models effectively without requiring premium hardware."
      ],
      "metadata": {
        "id": "J-ARAn4TWIaY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate launch -m axolotl.cli.train basic_train.yml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WKK6Z0toM9J",
        "outputId": "37a43c97-5762-48cd-8bae-339c3fc74783"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
            "\t`--num_processes` was set to a value of `1`\n",
            "\t`--num_machines` was set to a value of `1`\n",
            "\t`--mixed_precision` was set to a value of `'no'`\n",
            "\t`--dynamo_backend` was set to a value of `'no'`\n",
            "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
            "2024-12-27 14:54:49.328493: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-12-27 14:54:49.346147: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-27 14:54:49.366959: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-27 14:54:49.373318: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-27 14:54:49.388517: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-27 14:54:50.435620: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "[2024-12-27 14:54:52,940] [INFO] [datasets.<module>:54] [PID:6552] PyTorch version 2.5.1+cu121 available.\n",
            "[2024-12-27 14:54:52,941] [INFO] [datasets.<module>:66] [PID:6552] Polars version 1.9.0 available.\n",
            "[2024-12-27 14:54:52,942] [INFO] [datasets.<module>:77] [PID:6552] Duckdb version 1.1.3 available.\n",
            "[2024-12-27 14:54:52,943] [INFO] [datasets.<module>:112] [PID:6552] TensorFlow version 2.17.1 available.\n",
            "[2024-12-27 14:54:52,944] [INFO] [datasets.<module>:125] [PID:6552] JAX version 0.4.33 available.\n",
            "[2024-12-27 14:54:55,199] [INFO] [real_accelerator.py:219:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
            "df: /root/.triton/autotune: No such file or directory\n",
            "[2024-12-27 14:54:55,293] [INFO] [root.spawn:60] [PID:6552] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmpjqojxvwv/test.c -o /tmp/tmpjqojxvwv/test.o\n",
            "[2024-12-27 14:54:55,311] [INFO] [root.spawn:60] [PID:6552] x86_64-linux-gnu-gcc /tmp/tmpjqojxvwv/test.o -laio -o /tmp/tmpjqojxvwv/a.out\n",
            "[2024-12-27 14:54:55,964] [INFO] [root.spawn:60] [PID:6552] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmp7zkq00fg/test.c -o /tmp/tmp7zkq00fg/test.o\n",
            "[2024-12-27 14:54:55,981] [INFO] [root.spawn:60] [PID:6552] x86_64-linux-gnu-gcc /tmp/tmp7zkq00fg/test.o -L/usr/local/cuda -L/usr/local/cuda/lib64 -lcufile -o /tmp/tmp7zkq00fg/a.out\n",
            "[2024-12-27 14:54:56,029] [INFO] [root.spawn:60] [PID:6552] x86_64-linux-gnu-gcc -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -c /tmp/tmppwapssd8/test.c -o /tmp/tmppwapssd8/test.o\n",
            "[2024-12-27 14:54:56,046] [INFO] [root.spawn:60] [PID:6552] x86_64-linux-gnu-gcc /tmp/tmppwapssd8/test.o -laio -o /tmp/tmppwapssd8/a.out\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/monkeypatch/relora.py:16: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import ZeroRedundancyOptimizer\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "\u001b[33m[2024-12-27 14:54:59,686] [WARNING] [axolotl.utils.config.models.input.hint_batch_size_set:480] [PID:6552] [RANK:0] batch_size is not recommended. Please use gradient_accumulation_steps instead.\n",
            "To calculate the equivalent gradient_accumulation_steps, divide batch_size / micro_batch_size / number of gpus.\u001b[39m\n",
            "[2024-12-27 14:54:59,719] [DEBUG] [axolotl.normalize_config:87] [PID:6552] [RANK:0] bf16 support detected, enabling for this configuration.\u001b[39m\n",
            "config.json: 100% 608/608 [00:00<00:00, 4.18MB/s]\n",
            "[2024-12-27 14:54:59,931] [INFO] [axolotl.normalize_config:211] [PID:6552] [RANK:0] cuda memory usage baseline: 0.000GB (+0.441GB misc)\u001b[39m\n",
            "\n",
            "     #@@ #@@      @@# @@#\n",
            "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
            "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
            "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
            "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
            "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
            "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
            "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
            "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
            "    @@@@  @@@@@@@@@@@@@@@@\n",
            "\n",
            "\u001b[33m[2024-12-27 14:54:59,949] [WARNING] [axolotl.scripts.check_user_token:565] [PID:6552] [RANK:0] Error verifying HuggingFace token. Remember to log in using `huggingface-cli login` and get your access token from https://huggingface.co/settings/tokens if you want to use gated models or datasets.\u001b[39m\n",
            "tokenizer_config.json: 100% 1.29k/1.29k [00:00<00:00, 12.5MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 9.72MB/s]\n",
            "special_tokens_map.json: 100% 551/551 [00:00<00:00, 4.51MB/s]\n",
            "tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 13.5MB/s]\n",
            "[2024-12-27 14:55:01,139] [DEBUG] [axolotl.load_tokenizer:296] [PID:6552] [RANK:0] EOS: 2 / </s>\u001b[39m\n",
            "[2024-12-27 14:55:01,139] [DEBUG] [axolotl.load_tokenizer:297] [PID:6552] [RANK:0] BOS: 1 / <s>\u001b[39m\n",
            "[2024-12-27 14:55:01,139] [DEBUG] [axolotl.load_tokenizer:298] [PID:6552] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
            "[2024-12-27 14:55:01,139] [DEBUG] [axolotl.load_tokenizer:299] [PID:6552] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
            "[2024-12-27 14:55:01,139] [INFO] [axolotl.load_tokenizer:313] [PID:6552] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2024-12-27 14:55:01,140] [INFO] [axolotl.load_tokenized_prepared_datasets:216] [PID:6552] [RANK:0] Unable to find prepared dataset in last_run_prepared/3898d389d5c46cccab10a46129a90578\u001b[39m\n",
            "[2024-12-27 14:55:01,140] [INFO] [axolotl.load_tokenized_prepared_datasets:217] [PID:6552] [RANK:0] Loading raw datasets...\u001b[39m\n",
            "\u001b[33m[2024-12-27 14:55:01,140] [WARNING] [axolotl.load_tokenized_prepared_datasets:219] [PID:6552] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
            "[2024-12-27 14:55:01,140] [INFO] [axolotl.load_tokenized_prepared_datasets:226] [PID:6552] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
            "README.md: 100% 404/404 [00:00<00:00, 2.77MB/s]\n",
            "(…)-00000-of-00001-532ad934f217d092.parquet: 100% 130k/130k [00:00<00:00, 1.61MB/s]\n",
            "Generating train split: 100% 100/100 [00:00<00:00, 2514.47 examples/s]\n",
            "[2024-12-27 14:55:03,462] [INFO] [axolotl.get_dataset_wrapper:613] [PID:6552] [RANK:0] Loading dataset with base_type: None and prompt_style: None\u001b[39m\n",
            "Tokenizing Prompts (num_proc=12): 100% 100/100 [00:00<00:00, 334.56 examples/s]\n",
            "[2024-12-27 14:55:03,952] [INFO] [axolotl.load_tokenized_prepared_datasets:486] [PID:6552] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/3898d389d5c46cccab10a46129a90578\u001b[39m\n",
            "Saving the dataset (1/1 shards): 100% 100/100 [00:00<00:00, 13320.33 examples/s]\n",
            "[2024-12-27 14:55:03,968] [DEBUG] [axolotl.calculate_total_num_steps:342] [PID:6552] [RANK:0] total_num_tokens: 48_334\u001b[39m\n",
            "[2024-12-27 14:55:03,969] [DEBUG] [axolotl.calculate_total_num_steps:360] [PID:6552] [RANK:0] `total_supervised_tokens: 45_123`\u001b[39m\n",
            "[2024-12-27 14:55:03,970] [DEBUG] [axolotl.calculate_total_num_steps:438] [PID:6552] [RANK:0] total_num_steps: 50\u001b[39m\n",
            "[2024-12-27 14:55:03,970] [DEBUG] [axolotl.train.train:66] [PID:6552] [RANK:0] loading tokenizer... TinyLlama/TinyLlama-1.1B-Chat-v1.0\u001b[39m\n",
            "[2024-12-27 14:55:04,259] [DEBUG] [axolotl.load_tokenizer:296] [PID:6552] [RANK:0] EOS: 2 / </s>\u001b[39m\n",
            "[2024-12-27 14:55:04,259] [DEBUG] [axolotl.load_tokenizer:297] [PID:6552] [RANK:0] BOS: 1 / <s>\u001b[39m\n",
            "[2024-12-27 14:55:04,259] [DEBUG] [axolotl.load_tokenizer:298] [PID:6552] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
            "[2024-12-27 14:55:04,259] [DEBUG] [axolotl.load_tokenizer:299] [PID:6552] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
            "[2024-12-27 14:55:04,259] [INFO] [axolotl.load_tokenizer:313] [PID:6552] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
            "[2024-12-27 14:55:04,259] [DEBUG] [axolotl.train.train:98] [PID:6552] [RANK:0] loading model\u001b[39m\n",
            "[2024-12-27 14:55:04,368] [INFO] [axolotl.monkeypatch.trainer_grad_accum.patch_forward_for_ga:203] [PID:6552] [RANK:0] patching forward\u001b[39m\n",
            "model.safetensors: 100% 2.20G/2.20G [00:51<00:00, 42.5MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 1.09MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/axolotl/core/trainer_builder.py:444: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `AxolotlTrainer.__init__`. Use `processing_class` instead.\n",
            "  super().__init__(*_args, **kwargs)\n",
            "[2024-12-27 14:55:59,045] [INFO] [axolotl.train.train:178] [PID:6552] [RANK:0] Starting trainer...\u001b[39m\n",
            "{'loss': 1.2722, 'grad_norm': 5.945902347564697, 'learning_rate': 0.0001, 'epoch': 0.04}\n",
            "  2% 1/50 [00:01<01:28,  1.81s/it][2024-12-27 14:56:01,494] [INFO] [axolotl.callbacks.on_step_end:130] [PID:6552] [RANK:0] cuda memory usage while training: 4.391GB (+7.646GB cache, +0.948GB misc)\u001b[39m\n",
            "{'loss': 1.272, 'grad_norm': 6.059275150299072, 'learning_rate': 0.0002, 'epoch': 0.08}\n",
            "{'loss': 2.0305, 'grad_norm': 17.282867431640625, 'learning_rate': 0.00019978589232386035, 'epoch': 0.12}\n",
            "{'loss': 2.2591, 'grad_norm': 9.657120704650879, 'learning_rate': 0.00019914448613738106, 'epoch': 0.16}\n",
            "{'loss': 2.1259, 'grad_norm': 7.107264518737793, 'learning_rate': 0.00019807852804032305, 'epoch': 0.2}\n",
            "{'loss': 2.0636, 'grad_norm': 8.853582382202148, 'learning_rate': 0.00019659258262890683, 'epoch': 0.24}\n",
            "{'loss': 2.2149, 'grad_norm': 6.435313701629639, 'learning_rate': 0.0001946930129495106, 'epoch': 0.28}\n",
            "{'loss': 2.1753, 'grad_norm': 6.681417465209961, 'learning_rate': 0.0001923879532511287, 'epoch': 0.32}\n",
            "{'loss': 2.1523, 'grad_norm': 6.584863662719727, 'learning_rate': 0.00018968727415326884, 'epoch': 0.36}\n",
            "{'loss': 2.3055, 'grad_norm': 8.162365913391113, 'learning_rate': 0.00018660254037844388, 'epoch': 0.4}\n",
            "{'loss': 2.1104, 'grad_norm': 6.101772785186768, 'learning_rate': 0.00018314696123025454, 'epoch': 0.44}\n",
            "{'loss': 2.0873, 'grad_norm': 5.3202900886535645, 'learning_rate': 0.00017933533402912354, 'epoch': 0.48}\n",
            "{'loss': 2.3718, 'grad_norm': 5.356533527374268, 'learning_rate': 0.00017518398074789775, 'epoch': 0.52}\n",
            "{'loss': 2.3551, 'grad_norm': 6.189451694488525, 'learning_rate': 0.00017071067811865476, 'epoch': 0.56}\n",
            "{'loss': 2.0983, 'grad_norm': 5.574389934539795, 'learning_rate': 0.00016593458151000688, 'epoch': 0.6}\n",
            "{'loss': 2.3172, 'grad_norm': 6.019486904144287, 'learning_rate': 0.00016087614290087208, 'epoch': 0.64}\n",
            "{'loss': 2.1882, 'grad_norm': 33.28673553466797, 'learning_rate': 0.00015555702330196023, 'epoch': 0.68}\n",
            "{'loss': 4.6356, 'grad_norm': 2493.3466796875, 'learning_rate': 0.00015000000000000001, 'epoch': 0.72}\n",
            "{'loss': 2.1059, 'grad_norm': 9.282798767089844, 'learning_rate': 0.00014422886902190014, 'epoch': 0.76}\n",
            "{'loss': 2.3086, 'grad_norm': 6.158080101013184, 'learning_rate': 0.000138268343236509, 'epoch': 0.8}\n",
            "{'loss': 2.2543, 'grad_norm': 5.0905232429504395, 'learning_rate': 0.00013214394653031616, 'epoch': 0.84}\n",
            "{'loss': 2.2337, 'grad_norm': 5.159426689147949, 'learning_rate': 0.00012588190451025207, 'epoch': 0.88}\n",
            "{'loss': 2.2541, 'grad_norm': 4.580943584442139, 'learning_rate': 0.00011950903220161285, 'epoch': 0.92}\n",
            "{'loss': 2.3081, 'grad_norm': 4.8574018478393555, 'learning_rate': 0.00011305261922200519, 'epoch': 0.96}\n",
            "{'loss': 2.022, 'grad_norm': 5.075265884399414, 'learning_rate': 0.00010654031292301432, 'epoch': 1.0}\n",
            "{'loss': 1.1296, 'grad_norm': 5.525472164154053, 'learning_rate': 0.0001, 'epoch': 1.04}\n",
            "{'loss': 1.0002, 'grad_norm': 3.8214261531829834, 'learning_rate': 9.345968707698569e-05, 'epoch': 1.08}\n",
            "{'loss': 1.2124, 'grad_norm': 4.345859527587891, 'learning_rate': 8.694738077799488e-05, 'epoch': 1.12}\n",
            "{'loss': 0.7134, 'grad_norm': 3.8112692832946777, 'learning_rate': 8.049096779838719e-05, 'epoch': 1.16}\n",
            "{'loss': 0.777, 'grad_norm': 3.9310784339904785, 'learning_rate': 7.411809548974792e-05, 'epoch': 1.2}\n",
            "{'loss': 0.7462, 'grad_norm': 3.8482015132904053, 'learning_rate': 6.785605346968386e-05, 'epoch': 1.24}\n",
            "{'loss': 1.2045, 'grad_norm': 4.876279830932617, 'learning_rate': 6.173165676349103e-05, 'epoch': 1.28}\n",
            "{'loss': 0.8418, 'grad_norm': 4.129216194152832, 'learning_rate': 5.577113097809989e-05, 'epoch': 1.32}\n",
            "{'loss': 0.918, 'grad_norm': 4.371517658233643, 'learning_rate': 5.000000000000002e-05, 'epoch': 1.36}\n",
            "{'loss': 0.6797, 'grad_norm': 3.4780547618865967, 'learning_rate': 4.444297669803981e-05, 'epoch': 1.4}\n",
            "{'loss': 0.675, 'grad_norm': 3.5653514862060547, 'learning_rate': 3.9123857099127936e-05, 'epoch': 1.44}\n",
            "{'loss': 0.9162, 'grad_norm': 4.751934051513672, 'learning_rate': 3.406541848999312e-05, 'epoch': 1.48}\n",
            "{'loss': 1.1364, 'grad_norm': 4.58274507522583, 'learning_rate': 2.9289321881345254e-05, 'epoch': 1.52}\n",
            "{'loss': 0.8594, 'grad_norm': 4.025010108947754, 'learning_rate': 2.4816019252102273e-05, 'epoch': 1.56}\n",
            "{'loss': 0.7227, 'grad_norm': 4.2811784744262695, 'learning_rate': 2.0664665970876496e-05, 'epoch': 1.6}\n",
            "{'loss': 0.8691, 'grad_norm': 4.239848613739014, 'learning_rate': 1.6853038769745467e-05, 'epoch': 1.64}\n",
            "{'loss': 0.8985, 'grad_norm': 4.717401027679443, 'learning_rate': 1.339745962155613e-05, 'epoch': 1.68}\n",
            "{'loss': 0.7157, 'grad_norm': 3.736905097961426, 'learning_rate': 1.0312725846731175e-05, 'epoch': 1.72}\n",
            "{'loss': 0.8181, 'grad_norm': 4.695258140563965, 'learning_rate': 7.612046748871327e-06, 'epoch': 1.76}\n",
            "{'loss': 0.7581, 'grad_norm': 3.697852611541748, 'learning_rate': 5.306987050489442e-06, 'epoch': 1.8}\n",
            "{'loss': 0.763, 'grad_norm': 3.536815643310547, 'learning_rate': 3.40741737109318e-06, 'epoch': 1.84}\n",
            "{'loss': 0.7779, 'grad_norm': 5.439235687255859, 'learning_rate': 1.921471959676957e-06, 'epoch': 1.88}\n",
            "{'loss': 0.5869, 'grad_norm': 3.5355300903320312, 'learning_rate': 8.555138626189618e-07, 'epoch': 1.92}\n",
            "{'loss': 1.1134, 'grad_norm': 4.470274448394775, 'learning_rate': 2.141076761396521e-07, 'epoch': 1.96}\n",
            "{'loss': 0.8013, 'grad_norm': 3.6412322521209717, 'learning_rate': 0.0, 'epoch': 2.0}\n",
            "{'train_runtime': 57.5513, 'train_samples_per_second': 3.475, 'train_steps_per_second': 0.869, 'train_loss': 1.5431241261959077, 'epoch': 2.0}\n",
            "100% 50/50 [00:57<00:00,  1.15s/it]\n",
            "[2024-12-27 14:56:57,006] [INFO] [axolotl.train.train:195] [PID:6552] [RANK:0] Training Completed!!! Saving pre-trained model to ./models/evinai_TinyLlama_Storyteller\u001b[39m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install transformers from source - only needed for versions <= v4.34\n",
        "# pip install git+https://github.com/huggingface/transformers.git\n",
        "# pip install accelerate\n",
        "\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"/content/models/evinai_TinyLlama_Storyteller\", torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
        "\n",
        "# We use the tokenizer's chat template to format each message - see https://huggingface.co/docs/transformers/main/en/chat_templating\n",
        "messages = [\n",
        "    # {\n",
        "    #     \"role\": \"system\",\n",
        "    #     \"content\": \"You are a friendly chatbot who always responds in the style of a pirate\",\n",
        "    # },\n",
        "    {\"role\": \"user\", \"content\": \"A bright sudent was working with the Fuzzy cientist on a project.\"},\n",
        "]\n"
      ],
      "metadata": {
        "id": "rexuO3QolwhV",
        "outputId": "284448d1-0127-4378-86d2-10915aa69821",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "a0__dRc-om-R"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt"
      ],
      "metadata": {
        "id": "JMmJFGVyosc7",
        "outputId": "5d7f9553-5a3e-4097-c954-8538c37b5e2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|user|>\\na bright sudent was working with the Fuzzy scientist on a project.</s>\\n<|assistant|>\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = pipe(prompt, max_new_tokens=512)"
      ],
      "metadata": {
        "id": "OxJUs4bKousr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "UkJvjmy7o9w1",
        "outputId": "f7eec539-6862-450e-a224-12a210784ff0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|user|>\n",
            "A bright sudent was working with the Fuzzy cientist on a project.</s>\n",
            "<|assistant|>\n",
            "Armed with a bachelor's degree in cognitive science, Jack had always felt like there was something missing from his life. He had always been interested in the study of mental health, but he never imagined what it would be like for him to develop a cure for a high-profile researcher.\n",
            "\n",
            "One day, as he sat at his desk, Jack heard a knock on his door. The knock was on his door and there was no name on it. It was unclear who was calling for help, so he opened the door to find a curious researcher named Dr. Jameson.\n",
            "\n",
            "\"Can I help you?\" Jack asked, kindly.\n",
            "\n",
            "Dr. Jameson replied that he could help but his expertise was limited. \"I've got everything I need to get you the cure. The science is in the lab,\" he said, hoping that that was enough to make it go through to Jack.\n",
            "\n",
            "\"Ok, Jack. I've got this. The scientist and the engineer have both agreed to work with you in the lab, and they'll put up with any cost,\" Dr. Jameson said, trying to reassure him.\n",
            "\n",
            "Jack didn't know what it was all about, but he agreed to be partying with the scientist and the engineer to help them in their mission to find a cure for the high-profile researcher.\n",
            "\n",
            "The friendship was built on a mutual respect for their shared goal and the trust they felt each other possessed. Jack soon began to develop a special relationship with the scientist and the engineer, always communicating through their shared shared experiences.\n",
            "\n",
            "As they got closer to their friendship, Jack felt a sense of security growing around them. He was confident that he could trust Dr. Jameson and that together they had a winning team. They worked together, mixing compounds and testing them on lab mice.\n",
            "\n",
            "Finally, they had something that worked. The researchers and the scientist and the engineer had achieved the first time of their lives. Jack was ecstatic as he watched his life flash before his eyes. He had turned into a partying boy, always looking for new opportunities to socialize.\n",
            "\n",
            "As they moved towards the after-party, Jack didn't know where to start. The excitement was spreading too quickly for him to ignore the dread that clutched his chest. But as he was thrown around the corner,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = pipe(prompt, max_new_tokens=512)\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "metadata": {
        "id": "vDcAHq0ppAXW",
        "outputId": "79ef05cc-f242-466e-db0d-16cca5e6e727",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|user|>\n",
            "A bright sudent was working with the Fuzzy cientist on a project.</s>\n",
            "<|assistant|>\n",
            "Dr. Alexis wasn't one for a spotlight, but he had to do his job. He sat in a small laboratory, working with the fuzzy cientist, who was determined to make a cure for his cancer patient.\n",
            "\n",
            "The researchers were working tirelessly, analyzing the data from the patient's bloodstream and the survival patterns of the various tumors that had been used as a test. They were determined to find a cure that was both simple and easy to use.\n",
            "\n",
            "The doctor started by analyzing the data from the patient's blood and the survival patterns of the cancer tissues. The results of the review were staggering. It was found that the cancer patient was in a much better condition than had been initially thought, and the drug could help him to live longer.\n",
            "\n",
            "The doctor knew the stakes were high, but the only way to judge the effectiveness of the drug was to subject it to a rigorous test that was done on lab mice. He spent weeks testing the doses of the cure on lab mice who had never been exposed to the patient's cancer.\n",
            "\n",
            "Days turned into weeks as the doctor worked tirelessly, testing the cure on lab mice. The results were a mixed bag. Some mice were responsive, and others were not. It was clear that something wasn't right when they first started.\n",
            "\n",
            "Finally, a breakthrough was made when the doctor discovered that the cancer patient was not only a single patient but an individual with a unique set of characteristics. He had a condition that had been previously undiagnosed, and the drug was able to cure him of that using his specialized knowledge.\n",
            "\n",
            "Dr. Alexis knew that the journey ahead would be long and difficult. But he also knew that without the hope of a cure, he couldn't let his mission be a failure. He started working towards a cure for the patient's sake, and after a while, it became a routine.\n",
            "\n",
            "Slowly but surely, the once apathetic and reserved-spirited young man was finding his way in a strange and dangerous world. He had overcome his fears and his parasons, and now he was ready to bring his bright future, even in the face of such adversity.\n",
            "\n",
            "As the doctor walked past the lab mice, he couldn't help but feel a sense of\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "BRumfUCbpQQ-",
        "outputId": "2e4c51c2-4720-4330-b327-50f94a6d8420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To log in, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Enter your token (input will not be visible): \n",
            "Add token as git credential? (Y/n) hf_JwWLyEjuqOXHsgKzGruNiuHvjqyKLLybumY\n",
            "Invalid input. Must be one of ('y', 'yes', '1', 'n', 'no', '0', '')\n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: write).\n",
            "The token `stable` has been saved to /root/.cache/huggingface/stored_tokens\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful.\n",
            "The current active token is: `stable`\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global credential.helper store\n"
      ],
      "metadata": {
        "id": "pDMgxcxgscvi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli repo create tiny_llama_story_v1"
      ],
      "metadata": {
        "id": "YmMaX-ZMtFOd",
        "outputId": "1c000e14-a4c3-4e3d-86ee-9ccb4d7afe3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[90mgit version 2.34.1\u001b[0m\n",
            "\u001b[90mgit-lfs/3.0.2 (GitHub; linux amd64; go 1.18.1)\u001b[0m\n",
            "\n",
            "You are about to create \u001b[1mevinai/tiny_llama_story_v1\u001b[0m\n",
            "Proceed? [Y/n] y\n",
            "\n",
            "Your repo now lives at:\n",
            "  \u001b[1mhttps://huggingface.co/evinai/tiny_llama_story_v1\u001b[0m\n",
            "\n",
            "You can clone it locally with the command below, and commit/push as usual.\n",
            "\n",
            "  git clone https://huggingface.co/evinai/tiny_llama_story_v1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j3-uyRkatUc1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}